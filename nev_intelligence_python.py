#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–°èƒ½æºæ±½è½¦æƒ…æŠ¥æ”¶é›†ç³»ç»Ÿ - Pythonç‰ˆæœ¬
æ— éœ€Node.jsç¯å¢ƒï¼Œç«‹å³å¯ç”¨
ä½œè€…: NEV Intelligence Team
åˆ›å»ºæ—¶é—´: 2025å¹´11æœˆ28æ—¥
"""

import requests
import json
import time
import hashlib
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import re
import os
from dataclasses import dataclass
from enum import Enum

# æ•°æ®ç±»å‹å®šä¹‰
class DataCategory(Enum):
    SALES = "sales"
    NEW_MODEL = "new_model"
    COMPLAINT = "complaint"
    POLICY = "policy"
    REVIEW = "review"
    FORUM = "forum"
    NEWS = "news"
    LEADER_STATEMENT = "leader_statement"

class Sentiment(Enum):
    POSITIVE = "positive"
    NEGATIVE = "negative"
    NEUTRAL = "neutral"

@dataclass
class DataItem:
    id: str
    title: str
    content: str
    category: DataCategory
    source: str
    publish_date: str
    importance: int  # 1-5
    sentiment: Sentiment
    data_type: str  # fact, opinion, prediction
    verification_status: str = "pending"
    brand: Optional[str] = None
    model: Optional[str] = None
    url: Optional[str] = None
    metadata: Dict[str, Any] = None

@dataclass
class SalesData(DataItem):
    sales_volume: int = 0
    price_range: str = ""
    market_segment: str = ""
    growth_rate: float = 0.0

@dataclass
class NewModelData(DataItem):
    specifications: Dict[str, Any] = None
    target_market: str = ""
    launch_date: str = ""
    price_range: str = ""

@dataclass
class ComplaintData(DataItem):
    complaint_type: str = ""
    frequency: int = 1
    severity: int = 1  # 1-5

@dataclass
class LeaderStatement(DataItem):
    leader_name: str = ""
    company: str = ""
    source_type: str = ""  # weibo, interview, speech
    strategic_level: str = "tactical"  # tactical, strategic, visionary
    related_topics: List[str] = None

# ä¹˜è”ä¼šæ•°æ®é‡‡é›†å™¨
class CPCACollector:
    """ä¹˜è”ä¼šå®˜æ–¹æ•°æ®é‡‡é›†å™¨"""
    
    def __init__(self):
        self.base_url = "http://www.cpca.org.cn"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
    
    def collect_daily_data(self) -> List[DataItem]:
        """é‡‡é›†å½“æ—¥ä¹˜è”ä¼šæ•°æ®"""
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] å¼€å§‹é‡‡é›†ä¹˜è”ä¼šæ•°æ®...")
        
        results = []
        
        try:
            # æ¨¡æ‹Ÿé‡‡é›†é”€é‡æ•°æ®
            results.extend(self._collect_sales_data())
            
            # æ¨¡æ‹Ÿé‡‡é›†æ–°è½¦å‹æ•°æ®
            results.extend(self._collect_new_models())
            
            # æ¨¡æ‹Ÿé‡‡é›†æŠ•è¯‰æ•°æ®
            results.extend(self._collect_complaints())
            
            # æ¨¡æ‹Ÿé‡‡é›†æ”¿ç­–æ•°æ®
            results.extend(self._collect_policies())
            
            print(f"âœ… ä¹˜è”ä¼šæ•°æ®é‡‡é›†å®Œæˆï¼Œå…± {len(results)} æ¡")
            return results
            
        except Exception as e:
            print(f"âŒ ä¹˜è”ä¼šæ•°æ®é‡‡é›†å¤±è´¥: {e}")
            return []
    
    def _collect_sales_data(self) -> List[SalesData]:
        """é‡‡é›†é”€é‡æ•°æ®"""
        # æ¨¡æ‹Ÿæ•°æ® - å®é™…åº”ç”¨ä¸­éœ€è¦å®ç°çœŸå®çš„ç½‘é¡µçˆ¬å–
        mock_sales = [
            {
                "title": "æ¯”äºšè¿ªæ±‰EV 10æœˆé”€é‡åˆ›æ–°é«˜",
                "content": "æ¯”äºšè¿ªæ±‰EV 10æœˆé”€é‡è¾¾åˆ°15000è¾†ï¼Œç¯æ¯”å¢é•¿25%ï¼Œåˆ›å†å²æ–°é«˜",
                "brand": "æ¯”äºšè¿ª",
                "model": "æ±‰EV",
                "sales_volume": 15000,
                "price_range": "20-30ä¸‡",
                "market_segment": "ä¸­å¤§å‹è½¿è½¦",
                "growth_rate": 25.0,
                "publish_date": datetime.now().strftime('%Y-%m-%d')
            },
            {
                "title": "ç‰¹æ–¯æ‹‰Model Yé”€é‡ç¨³æ­¥å¢é•¿",
                "content": "ç‰¹æ–¯æ‹‰Model Y 10æœˆé”€é‡12000è¾†ï¼Œåœ¨è±ªåç”µåŠ¨SUVå¸‚åœºè¡¨ç°ä¼˜å¼‚",
                "brand": "ç‰¹æ–¯æ‹‰",
                "model": "Model Y",
                "sales_volume": 12000,
                "price_range": "30-40ä¸‡",
                "market_segment": "è±ªåSUV",
                "growth_rate": 15.0,
                "publish_date": datetime.now().strftime('%Y-%m-%d')
            }
        ]
        
        results = []
        for item in mock_sales:
            data_id = hashlib.md5(f"cpca_sales_{item['title']}".encode()).hexdigest()[:16]
            results.append(SalesData(
                id=data_id,
                title=item["title"],
                content=item["content"],
                category=DataCategory.SALES,
                source="ä¹˜è”ä¼š",
                publish_date=item["publish_date"],
                importance=self._calculate_importance(item["title"], item["content"]),
                sentiment=Sentiment.POSITIVE,
                data_type="fact",
                brand=item["brand"],
                model=item["model"],
                sales_volume=item["sales_volume"],
                price_range=item["price_range"],
                market_segment=item["market_segment"],
                growth_rate=item["growth_rate"]
            ))
        
        return results
    
    def _collect_new_models(self) -> List[NewModelData]:
        """é‡‡é›†æ–°è½¦å‹æ•°æ®"""
        mock_models = [
            {
                "title": "ç†æƒ³L9æ­£å¼ä¸Šå¸‚",
                "content": "ç†æƒ³æ±½è½¦å…¨æ–°å…¨å°ºå¯¸SUV L9æ­£å¼ä¸Šå¸‚ï¼Œå”®ä»·45.98ä¸‡å…ƒèµ·ï¼Œä¸»æ‰“å®¶åº­ç”¨æˆ·å¸‚åœº",
                "brand": "ç†æƒ³æ±½è½¦",
                "model": "L9",
                "price_range": "45-50ä¸‡",
                "target_market": "å®¶åº­ç”¨æˆ·",
                "launch_date": datetime.now().strftime('%Y-%m-%d'),
                "specifications": {"range": 1315, "battery": 44.5, "seats": 6}
            },
            {
                "title": "å°é¹G9å¼€å¯é¢„å”®",
                "content": "å°é¹æ±½è½¦å…¨æ–°ä¸­å¤§å‹SUV G9å¼€å¯é¢„å”®ï¼Œå”®ä»·30.99ä¸‡å…ƒèµ·ï¼Œé…å¤‡XPILOT 4.0æ™ºèƒ½é©¾é©¶ç³»ç»Ÿ",
                "brand": "å°é¹",
                "model": "G9",
                "price_range": "30-40ä¸‡",
                "target_market": "ç§‘æŠ€çˆ±å¥½è€…",
                "launch_date": (datetime.now() + timedelta(days=30)).strftime('%Y-%m-%d'),
                "specifications": {"range": 702, "battery": 98, "autonomous": "XPILOT 4.0"}
            }
        ]
        
        results = []
        for item in mock_models:
            data_id = hashlib.md5(f"cpca_model_{item['title']}".encode()).hexdigest()[:16]
            results.append(NewModelData(
                id=data_id,
                title=item["title"],
                content=item["content"],
                category=DataCategory.NEW_MODEL,
                source="ä¹˜è”ä¼š",
                publish_date=datetime.now().strftime('%Y-%m-%d'),
                importance=self._calculate_importance(item["title"], item["content"]),
                sentiment=Sentiment.POSITIVE,
                data_type="fact",
                brand=item["brand"],
                model=item["model"],
                specifications=item["specifications"],
                target_market=item["target_market"],
                launch_date=item["launch_date"]
            ))
        
        return results
    
    def _collect_complaints(self) -> List[ComplaintData]:
        """é‡‡é›†æŠ•è¯‰æ•°æ®"""
        mock_complaints = [
            {
                "title": "éƒ¨åˆ†æ¯”äºšè¿ªæ±‰EVç”¨æˆ·åæ˜ ç»­èˆªé—®é¢˜",
                "content": "éƒ¨åˆ†æ¯”äºšè¿ªæ±‰EVè½¦ä¸»åæ˜ å†¬å­£ç»­èˆªé‡Œç¨‹ä¸‹é™æ˜æ˜¾ï¼Œä¸å®˜æ–¹æ ‡ç§°å­˜åœ¨å·®è·",
                "brand": "æ¯”äºšè¿ª",
                "model": "æ±‰EV",
                "complaint_type": "ç»­èˆªé—®é¢˜",
                "severity": 3,
                "frequency": 15
            },
            {
                "title": "ç‰¹æ–¯æ‹‰Model 3å……ç”µæ•…éšœæŠ•è¯‰å¢åŠ ",
                "content": "éƒ¨åˆ†ç‰¹æ–¯æ‹‰Model 3è½¦ä¸»é‡åˆ°å……ç”µæ¡©å…¼å®¹æ€§é—®é¢˜ï¼Œå½±å“æ­£å¸¸ä½¿ç”¨",
                "brand": "ç‰¹æ–¯æ‹‰",
                "model": "Model 3",
                "complaint_type": "å……ç”µé—®é¢˜",
                "severity": 4,
                "frequency": 8
            }
        ]
        
        results = []
        for item in mock_complaints:
            data_id = hashlib.md5(f"cpca_complaint_{item['title']}".encode()).hexdigest()[:16]
            results.append(ComplaintData(
                id=data_id,
                title=item["title"],
                content=item["content"],
                category=DataCategory.COMPLAINT,
                source="ä¹˜è”ä¼š",
                publish_date=datetime.now().strftime('%Y-%m-%d'),
                importance=item["severity"],
                sentiment=Sentiment.NEGATIVE,
                data_type="fact",
                brand=item["brand"],
                model=item["model"],
                complaint_type=item["complaint_type"],
                severity=item["severity"],
                frequency=item["frequency"]
            ))
        
        return results
    
    def _collect_policies(self) -> List[DataItem]:
        """é‡‡é›†æ”¿ç­–æ•°æ®"""
        mock_policies = [
            {
                "title": "æ–°èƒ½æºæ±½è½¦è´­ç½®ç¨å‡å…æ”¿ç­–å»¶ç»­",
                "content": "è´¢æ”¿éƒ¨å®£å¸ƒæ–°èƒ½æºæ±½è½¦è´­ç½®ç¨å‡å…æ”¿ç­–å»¶ç»­è‡³2025å¹´åº•ï¼Œå•è½¦å‡å…é¢åº¦ä¸è¶…è¿‡3ä¸‡å…ƒ",
                "policy_type": "è´­ç½®ç¨æ”¿ç­–",
                "scope": "å…¨å›½",
                "effective_date": datetime.now().strftime('%Y-%m-%d')
            },
            {
                "title": "å……ç”µåŸºç¡€è®¾æ–½å»ºè®¾è¡¥è´´æ”¿ç­–å‡ºå°",
                "content": "å›½å®¶å‘æ”¹å§”å‘å¸ƒå……ç”µåŸºç¡€è®¾æ–½å»ºè®¾è¡¥è´´æ”¿ç­–ï¼Œå¯¹æ–°å»ºå……ç”µæ¡©ç»™äºˆæ¯åƒç“¦200å…ƒè¡¥è´´",
                "policy_type": "åŸºç¡€è®¾æ–½è¡¥è´´",
                "scope": "å…¨å›½",
                "effective_date": (datetime.now() + timedelta(days=30)).strftime('%Y-%m-%d')
            }
        ]
        
        results = []
        for item in mock_policies:
            data_id = hashlib.md5(f"cpca_policy_{item['title']}".encode()).hexdigest()[:16]
            results.append(DataItem(
                id=data_id,
                title=item["title"],
                content=item["content"],
                category=DataCategory.POLICY,
                source="ä¹˜è”ä¼š",
                publish_date=datetime.now().strftime('%Y-%m-%d'),
                importance=self._calculate_importance(item["title"], item["content"]),
                sentiment=Sentiment.POSITIVE,
                data_type="fact"
            ))
        
        return results
    
    def _calculate_importance(self, title: str, content: str) -> int:
        """è®¡ç®—é‡è¦æ€§è¯„åˆ†"""
        score = 1
        
        # å…³é”®è¯æƒé‡
        keywords = {
            'é”€é‡å† å†›': 5, 'ç¬¬ä¸€': 5, 'åˆ›çºªå½•': 4,
            'æ–°èƒ½æº': 3, 'ç”µåŠ¨è½¦': 3, 'æ™ºèƒ½æ±½è½¦': 3,
            'æŠ•è¯‰': 2, 'é—®é¢˜': 2, 'å¬å›': 4,
            'æ”¿ç­–': 4, 'è¡¥è´´': 4, 'è´­ç½®ç¨': 4
        }
        
        text = title + ' ' + content
        for keyword, weight in keywords.items():
            if keyword in text:
                score = max(score, weight)
        
        return min(score, 5)

# å‚ç›´å¹³å°ç›‘æµ‹å™¨
class VerticalPlatformMonitor:
    """å››å¤§æ±½è½¦å‚ç›´å¹³å°ç›‘æµ‹å™¨"""
    
    def __init__(self):
        self.platforms = {
            'autohome': {'name': 'æ±½è½¦ä¹‹å®¶', 'url': 'https://www.autohome.com.cn'},
            'dongchedi': {'name': 'æ‡‚è½¦å¸', 'url': 'https://www.dongchedi.com'},
            'yiche': {'name': 'æ˜“è½¦ç½‘', 'url': 'https://www.yiche.com'},
            'pcauto': {'name': 'å¤ªå¹³æ´‹æ±½è½¦', 'url': 'https://www.pcauto.com.cn'}
        }
        
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
    
    def monitor_all_platforms(self) -> List[DataItem]:
        """ç›‘æµ‹æ‰€æœ‰å¹³å°"""
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] å¼€å§‹ç›‘æµ‹å››å¤§æ±½è½¦å‚ç›´å¹³å°...")
        
        results = []
        
        for platform_key, platform_info in self.platforms.items():
            try:
                platform_data = self._monitor_single_platform(platform_key, platform_info)
                results.extend(platform_data)
                print(f"âœ… {platform_info['name']} æ•°æ®é‡‡é›†å®Œæˆ: {len(platform_data)} æ¡")
            except Exception as e:
                print(f"âŒ {platform_info['name']} æ•°æ®é‡‡é›†å¤±è´¥: {e}")
        
        print(f"âœ… å››å¤§å¹³å°ç›‘æµ‹å®Œæˆï¼Œå…± {len(results)} æ¡æ•°æ®")
        return results
    
    def _monitor_single_platform(self, platform_key: str, platform_info: dict) -> List[DataItem]:
        """ç›‘æµ‹å•ä¸ªå¹³å°"""
        results = []
        
        # æ¨¡æ‹Ÿé‡‡é›†æ–°è½¦ä¿¡æ¯
        results.extend(self._collect_new_cars(platform_key, platform_info))
        
        # æ¨¡æ‹Ÿé‡‡é›†ä¸“ä¸šè¯„æµ‹
        results.extend(self._collect_reviews(platform_key, platform_info))
        
        # æ¨¡æ‹Ÿé‡‡é›†ç”¨æˆ·è®ºå›
        results.extend(self._collect_forums(platform_key, platform_info))
        
        # æ¨¡æ‹Ÿé‡‡é›†æ–°é—»èµ„è®¯
        results.extend(self._collect_news(platform_key, platform_info))
        
        return results
    
    def _collect_new_cars(self, platform_key: str, platform_info: dict) -> List[DataItem]:
        """é‡‡é›†æ–°è½¦ä¿¡æ¯"""
        mock_data = [
            {
                "title": f"{platform_info['name']}ï¼šæ¯”äºšè¿ªæµ·è±¹è¯¦ç»†è§£æ",
                "content": f"{platform_info['name']}ç¼–è¾‘å›¢é˜Ÿå¯¹æ¯”äºšè¿ªæµ·è±¹è¿›è¡Œè¯¦ç»†å®æ‹è§£æï¼Œæ–°è½¦é¢„è®¡å”®ä»·22-28ä¸‡å…ƒ",
                "brand": "æ¯”äºšè¿ª",
                "model": "æµ·è±¹",
                "category": "new_car",
                "price_range": "22-28ä¸‡",
                "publish_date": datetime.now().strftime('%Y-%m-%d')
            },
            {
                "title": f"{platform_info['name']}ï¼šå°é¹G9åˆ°åº—å®æ‹",
                "content": f"{platform_info['name']}ç¼–è¾‘åœ¨ç»é”€å•†å¤„æ‹åˆ°å°é¹G9å®è½¦ï¼Œæ–°è½¦é…å¤‡æ¿€å…‰é›·è¾¾å’ŒXPILOT 4.0ç³»ç»Ÿ",
                "brand": "å°é¹",
                "model": "G9",
                "category": "new_car",
                "price_range": "30-40ä¸‡",
                "publish_date": datetime.now().strftime('%Y-%m-%d')
            }
        ]
        
        results = []
        for item in mock_data:
            data_id = hashlib.md5(f"{platform_key}_newcar_{item['title']}".encode()).hexdigest()[:16]
            results.append(DataItem(
                id=data_id,
                title=item["title"],
                content=item["content"],
                category=DataCategory.NEW_MODEL,
                source=platform_info['name'],
                publish_date=item["publish_date"],
                importance=self._calculate_platform_importance(item["title"], item["content"]),
                sentiment=Sentiment.POSITIVE,
                data_type="fact",
                brand=item["brand"],
                model=item["model"]
            ))
        
        return results
    
    def _collect_reviews(self, platform_key: str, platform_info: dict) -> List[DataItem]:
        """é‡‡é›†ä¸“ä¸šè¯„æµ‹"""
        mock_data = [
            {
                "title": f"{platform_info['name']}ï¼šç†æƒ³L9ä¸“ä¸šè¯•é©¾è¯„æµ‹",
                "content": f"{platform_info['name']}ä¸“ä¸šç¼–è¾‘æ·±åº¦è¯•é©¾ç†æƒ³L9ï¼Œå¯¹å…¶ç©ºé—´è¡¨ç°å’Œæ™ºèƒ½åŒ–é…ç½®ç»™äºˆé«˜åº¦è¯„ä»·",
                "brand": "ç†æƒ³æ±½è½¦",
                "model": "L9",
                "category": "review",
                "rating": 9.2,
                "publish_date": datetime.now().strftime('%Y-%m-%d')
            },
            {
                "title": f"{platform_info['name']}ï¼šè”šæ¥ET7æ·±åº¦æµ‹è¯•",
                "content": f"{platform_info['name']}æµ‹è¯•å›¢é˜Ÿå¯¹è”šæ¥ET7è¿›è¡Œä¸ºæœŸä¸€å‘¨çš„æ·±åº¦æµ‹è¯•ï¼Œç»­èˆªå’Œæ™ºèƒ½é©¾é©¶è¡¨ç°ä¼˜ç§€",
                "brand": "è”šæ¥",
                "model": "ET7",
                "category": "review",
                "rating": 8.8,
                "publish_date": datetime.now().strftime('%Y-%m-%d')
            }
        ]
        
        results = []
        for item in mock_data:
            data_id = hashlib.md5(f"{platform_key}_review_{item['title']}".encode()).hexdigest()[:16]
            results.append(DataItem(
                id=data_id,
                title=item["title"],
                content=item["content"],
                category=DataCategory.REVIEW,
                source=platform_info['name'],
                publish_date=item["publish_date"],
                importance=self._calculate_platform_importance(item["title"], item["content"]),
                sentiment=Sentiment.POSITIVE,
                data_type="opinion",
                brand=item["brand"],
                model=item["model"]
            ))
        
        return results
    
    def _collect_forums(self, platform_key: str, platform_info: dict) -> List[DataItem]:
        """é‡‡é›†ç”¨æˆ·è®ºå›"""
        mock_data = [
            {
                "title": f"{platform_info['name']}è®ºå›ï¼šæ¯”äºšè¿ªæ±‰EVè½¦ä¸»åˆ†äº«ç”¨è½¦ä½“éªŒ",
                "content": f"è½¦ä¸»åˆ†äº«ï¼šæ¯”äºšè¿ªæ±‰EVä½¿ç”¨åŠå¹´ï¼Œæ•´ä½“æ»¡æ„ï¼Œå†¬å­£ç»­èˆªæœ‰æ‰€ä¸‹é™ä½†å¯æ¥å—",
                "brand": "æ¯”äºšè¿ª",
                "model": "æ±‰EV",
                "category": "forum",
                "user_satisfaction": 4,
                "publish_date": datetime.now().strftime('%Y-%m-%d')
            },
            {
                "title": f"{platform_info['name']}è®ºå›ï¼šç‰¹æ–¯æ‹‰Model Yå……ç”µä½“éªŒåˆ†äº«",
                "content": f"è½¦ä¸»åˆ†äº«ï¼šç‰¹æ–¯æ‹‰Model Yåœ¨ç¬¬ä¸‰æ–¹å……ç”µæ¡©çš„å…¼å®¹æ€§é—®é¢˜ï¼Œå¸Œæœ›èƒ½æœ‰æ‰€æ”¹å–„",
                "brand": "ç‰¹æ–¯æ‹‰",
                "model": "Model Y",
                "category": "forum",
                "user_satisfaction": 3,
                "publish_date": datetime.now().strftime('%Y-%m-%d')
            }
        ]
        
        results = []
        for item in mock_data:
            data_id = hashlib.md5(f"{platform_key}_forum_{item['title']}".encode()).hexdigest()[:16]
            sentiment = Sentiment.POSITIVE if item["user_satisfaction"] >= 4 else Sentiment.NEGATIVE if item["user_satisfaction"] <= 2 else Sentiment.NEUTRAL
            
            results.append(DataItem(
                id=data_id,
                title=item["title"],
                content=item["content"],
                category=DataCategory.FORUM,
                source=platform_info['name'],
                publish_date=item["publish_date"],
                importance=item["user_satisfaction"],
                sentiment=sentiment,
                data_type="user_feedback",
                brand=item["brand"],
                model=item["model"]
            ))
        
        return results
    
    def _collect_news(self, platform_key: str, platform_info: dict) -> List[DataItem]:
        """é‡‡é›†æ–°é—»èµ„è®¯"""
        mock_data = [
            {
                "title": f"{platform_info['name']}ï¼šæ–°èƒ½æºæ±½è½¦é”€é‡æŒç»­å¢é•¿",
                "content": f"æ®{platform_info['name']}æŠ¥é“ï¼Œ10æœˆæ–°èƒ½æºæ±½è½¦é”€é‡åŒæ¯”å¢é•¿35%ï¼Œå¸‚åœºè¡¨ç°å¼ºåŠ²",
                "category": "news",
                "publish_date": datetime.now().strftime('%Y-%m-%d')
            },
            {
                "title": f"{platform_info['name']}ï¼šå……ç”µåŸºç¡€è®¾æ–½å»ºè®¾åŠ é€Ÿ",
                "content": f"{platform_info['name']}èµ„è®¯ï¼šå…¨å›½å……ç”µæ¡©æ•°é‡çªç ´1000ä¸‡ä¸ªï¼ŒåŸºç¡€è®¾æ–½å»ºè®¾æ­¥ä¼åŠ å¿«",
                "category": "news",
                "publish_date": datetime.now().strftime('%Y-%m-%d')
            }
        ]
        
        results = []
        for item in mock_data:
            data_id = hashlib.md5(f"{platform_key}_news_{item['title']}".encode()).hexdigest()[:16]
            results.append(DataItem(
                id=data_id,
                title=item["title"],
                content=item["content"],
                category=DataCategory.NEWS,
                source=platform_info['name'],
                publish_date=item["publish_date"],
                importance=self._calculate_platform_importance(item["title"], item["content"]),
                sentiment=Sentiment.POSITIVE,
                data_type="fact"
            ))
        
        return results
    
    def _calculate_platform_importance(self, title: str, content: str) -> int:
        """è®¡ç®—å¹³å°æ•°æ®é‡è¦æ€§"""
        score = 1
        
        # å…³é”®è¯æƒé‡
        keywords = {
            'æ–°èƒ½æº': 3, 'ç”µåŠ¨è½¦': 3, 'æ™ºèƒ½æ±½è½¦': 3,
            'é”€é‡': 2, 'ä¸Šå¸‚': 2, 'å‘å¸ƒ': 2,
            'è¯„æµ‹': 2, 'è¯•é©¾': 2, 'å¯¹æ¯”': 2,
            'æŠ•è¯‰': 3, 'é—®é¢˜': 2, 'æ•…éšœ': 3,
            'ç»­èˆª': 3, 'å……ç”µ': 3, 'ç”µæ± ': 3
        }
        
        text = title + ' ' + content
        for keyword, weight in keywords.items():
            if keyword in text:
                score = max(score, weight)
        
        return min(score, 5)

# è¡Œä¸šé¢†è¢–è¿½è¸ªå™¨
class IndustryLeaderTracker:
    """è¡Œä¸šé¢†è¢–åŠ¨æ€è¿½è¸ªå™¨"""
    
    def __init__(self):
        self.leaders = [
            {"id": "wang-chuanfu", "name": "ç‹ä¼ ç¦", "company": "æ¯”äºšè¿ª", "importance": 5},
            {"id": "li-shufu", "name": "æä¹¦ç¦", "company": "å‰åˆ©", "importance": 5},
            {"id": "wei-jianjun", "name": "é­å»ºå†›", "company": "é•¿åŸ", "importance": 4},
            {"id": "li-xiang", "name": "ææƒ³", "company": "ç†æƒ³æ±½è½¦", "importance": 4},
            {"id": "li-bin", "name": "ææ–Œ", "company": "è”šæ¥", "importance": 4},
            {"id": "he-xiaopeng", "name": "ä½•å°é¹", "company": "å°é¹", "importance": 4},
            {"id": "lei-jun", "name": "é›·å†›", "company": "å°ç±³æ±½è½¦", "importance": 5}
        ]
    
    def track_all_leaders(self) -> List[LeaderStatement]:
        """è¿½è¸ªæ‰€æœ‰è¡Œä¸šé¢†è¢–"""
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] å¼€å§‹è¿½è¸ªè¡Œä¸šé¢†è¢–åŠ¨æ€...")
        
        results = []
        
        for leader in self.leaders:
            try:
                leader_data = self._track_single_leader(leader)
                results.extend(leader_data)
                print(f"âœ… {leader['name']} ({leader['company']}) è¨€è®ºé‡‡é›†: {len(leader_data)} æ¡")
            except Exception as e:
                print(f"âŒ {leader['name']} è¿½è¸ªå¤±è´¥: {e}")
        
        print(f"âœ… è¡Œä¸šé¢†è¢–åŠ¨æ€è¿½è¸ªå®Œæˆï¼Œå…± {len(results)} æ¡è¨€è®º")
        return results
    
    def _track_single_leader(self, leader: dict) -> List[LeaderStatement]:
        """è¿½è¸ªå•ä¸ªé¢†è¢–"""
        results = []
        
        # æ¨¡æ‹Ÿå¾®åšåŠ¨æ€
        results.extend(self._collect_weibo_statements(leader))
        
        # æ¨¡æ‹Ÿé‡‡è®¿æŠ¥é“
        results.extend(self._collect_interview_statements(leader))
        
        # æ¨¡æ‹Ÿå…¬å¼€æ¼”è®²
        results.extend(self._collect_speech_statements(leader))
        
        return results
    
    def _collect_weibo_statements(self, leader: dict) -> List[LeaderStatement]:
        """é‡‡é›†å¾®åšè¨€è®º"""
        mock_statements = [
            {
                "content": f"{leader['name']}ï¼šæ–°èƒ½æºæ±½è½¦è¡Œä¸šæ­£è¿æ¥å‰æ‰€æœªæœ‰çš„å‘å±•æœºé‡ï¼ŒæŠ€æœ¯åˆ›æ–°æ˜¯å…³é”®",
                "source_type": "weibo",
                "category": "strategy",
                "strategic_level": "strategic"
            },
            {
                "content": f"{leader['name']}ï¼šæˆ‘ä»¬å°†ç»§ç»­åŠ å¤§ç ”å‘æŠ•å…¥ï¼Œæ¨åŠ¨æ™ºèƒ½åŒ–æŠ€æœ¯å‘å±•",
                "source_type": "weibo", 
                "category": "technology",
                "strategic_level": "tactical"
            }
        ]
        
        results = []
        for item in mock_statements:
            data_id = hashlib.md5(f"weibo_{leader['id']}_{item['content'][:50]}".encode()).hexdigest()[:16]
            results.append(LeaderStatement(
                id=data_id,
                title=f"{leader['name']}å¾®åšåŠ¨æ€",
                content=self._extract_key_points(item["content"]),
                category=DataCategory.LEADER_STATEMENT,
                source="å¾®åš",
                publish_date=datetime.now().strftime('%Y-%m-%d'),
                importance=leader["importance"],
                sentiment=self._analyze_sentiment(item["content"]),
                data_type="opinion",
                leader_name=leader["name"],
                company=leader["company"],
                source_type=item["source_type"],
                strategic_level=item["strategic_level"],
                related_topics=self._extract_related_topics(item["content"])
            ))
        
        return results
    
    def _collect_interview_statements(self, leader: dict) -> List[LeaderStatement]:
        """é‡‡é›†é‡‡è®¿è¨€è®º"""
        mock_statements = [
            {
                "content": f"{leader['name']}åœ¨æ¥å—åª’ä½“é‡‡è®¿æ—¶è¡¨ç¤ºï¼šæœªæ¥äº”å¹´å°†æ˜¯æ–°èƒ½æºæ±½è½¦å¸‚åœºçš„å…³é”®çª—å£æœŸ",
                "source_type": "interview",
                "category": "market",
                "strategic_level": "visionary"
            },
            {
                "content": f"{leader['name']}ï¼šæˆ‘ä»¬è®¡åˆ’åœ¨æœªæ¥ä¸‰å¹´å†…æ¨å‡º10æ¬¾æ–°èƒ½æºè½¦å‹ï¼Œè¦†ç›–å„ä¸ªç»†åˆ†å¸‚åœº",
                "source_type": "interview",
                "category": "strategy",
                "strategic_level": "strategic"
            }
        ]
        
        results = []
        for item in mock_statements:
            data_id = hashlib.md5(f"interview_{leader['id']}_{item['content'][:50]}".encode()).hexdigest()[:16]
            results.append(LeaderStatement(
                id=data_id,
                title=f"{leader['name']}é‡‡è®¿è§‚ç‚¹",
                content=self._extract_key_points(item["content"]),
                category=DataCategory.LEADER_STATEMENT,
                source="åª’ä½“é‡‡è®¿",
                publish_date=datetime.now().strftime('%Y-%m-%d'),
                importance=leader["importance"],
                sentiment=self._analyze_sentiment(item["content"]),
                data_type="opinion",
                leader_name=leader["name"],
                company=leader["company"],
                source_type=item["source_type"],
                strategic_level=item["strategic_level"],
                related_topics=self._extract_related_topics(item["content"])
            ))
        
        return results
    
    def _collect_speech_statements(self, leader: dict) -> List[LeaderStatement]:
        """é‡‡é›†æ¼”è®²è¨€è®º"""
        mock_statements = [
            {
                "content": f"{leader['name']}åœ¨æ±½è½¦è¡Œä¸šå³°ä¼šä¸Šè¡¨ç¤ºï¼šæ™ºèƒ½åŒ–ã€ç½‘è”åŒ–æ˜¯æ±½è½¦äº§ä¸šçš„æœªæ¥å‘å±•æ–¹å‘",
                "source_type": "speech",
                "category": "technology",
                "strategic_level": "visionary"
            },
            {
                "content": f"{leader['name']}ï¼šæˆ‘ä»¬è¦åšæŒæŠ€æœ¯åˆ›æ–°ï¼Œæ¨åŠ¨ä¸­å›½æ±½è½¦å“ç‰Œèµ°å‘ä¸–ç•Œ",
                "source_type": "speech",
                "category": "strategy",
                "strategic_level": "visionary"
            }
        ]
        
        results = []
        for item in mock_statements:
            data_id = hashlib.md5(f"speech_{leader['id']}_{item['content'][:50]}".encode()).hexdigest()[:16]
            results.append(LeaderStatement(
                id=data_id,
                title=f"{leader['name']}æ¼”è®²è§‚ç‚¹",
                content=self._extract_key_points(item["content"]),
                category=DataCategory.LEADER_STATEMENT,
                source="å…¬å¼€æ¼”è®²",
                publish_date=datetime.now().strftime('%Y-%m-%d'),
                importance=leader["importance"],
                sentiment=self._analyze_sentiment(item["content"]),
                data_type="opinion",
                leader_name=leader["name"],
                company=leader["company"],
                source_type=item["source_type"],
                strategic_level=item["strategic_level"],
                related_topics=self._extract_related_topics(item["content"])
            ))
        
        return results
    
    def _analyze_sentiment(self, content: str) -> Sentiment:
        """åˆ†ææƒ…æ„Ÿå€¾å‘"""
        positive_words = ['å¥½', 'æ£’', 'ä¼˜ç§€', 'é¢†å…ˆ', 'æˆåŠŸ', 'å¢é•¿', 'çªç ´', 'åˆ›æ–°', 'æ»¡æ„', 'ä¹è§‚']
        negative_words = ['å·®', 'å›°éš¾', 'æŒ‘æˆ˜', 'é—®é¢˜', 'æ‹…å¿§', 'é£é™©', 'å‹åŠ›', 'å±æœº', 'ä¸‹æ»‘', 'äºæŸ']
        
        positive_count = sum(1 for word in positive_words if word in content)
        negative_count = sum(1 for word in negative_words if word in content)
        
        if positive_count > negative_count:
            return Sentiment.POSITIVE
        elif negative_count > positive_count:
            return Sentiment.NEGATIVE
        else:
            return Sentiment.NEUTRAL
    
    def _extract_key_points(self, content: str) -> str:
        """æå–å…³é”®è¦ç‚¹"""
        # ç®€å•çš„å…³é”®è¦ç‚¹æå–
        sentences = content.split('ã€‚')
        key_sentences = [s.strip() for s in sentences if len(s.strip()) > 10][:2]
        return 'ã€‚'.join(key_sentences) + ('ã€‚' if key_sentences else '')
    
    def _extract_related_topics(self, content: str) -> List[str]:
        """æå–ç›¸å…³è¯é¢˜"""
        topics = ['æ–°èƒ½æº', 'ç”µåŠ¨è½¦', 'æ™ºèƒ½æ±½è½¦', 'è‡ªåŠ¨é©¾é©¶', 'æŠ€æœ¯', 'åˆ›æ–°', 'å¸‚åœº', 'æˆ˜ç•¥']
        return [topic for topic in topics if topic in content]

# æ•°æ®æ ‡å‡†åŒ–æ¨¡æ¿
class DataStandardizationTemplate:
    """æ•°æ®æ ‡å‡†åŒ–æ¨¡æ¿"""
    
    def generate_daily_report(self, data: List[DataItem]) -> dict:
        """ç”Ÿæˆæ ‡å‡†åŒ–æ—¥æŠ¥"""
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] å¼€å§‹ç”Ÿæˆæ ‡å‡†åŒ–æ—¥æŠ¥...")
        
        # æ•°æ®åˆ†ç±»ç»Ÿè®¡
        category_stats = self._categorize_data(data)
        
        # ç”ŸæˆæŠ¥å‘Šç»“æ„
        report = {
            "metadata": {
                "date": datetime.now().strftime('%Y-%m-%d'),
                "version": "1.0.0",
                "generated_at": datetime.now().isoformat(),
                "total_items": len(data),
                "data_summary": category_stats
            },
            "sections": {
                "executive_summary": self._generate_executive_summary(data),
                "sales_analysis": self._generate_sales_analysis(data),
                "new_models": self._generate_new_models_analysis(data),
                "user_feedback": self._generate_user_feedback(data),
                "policy_updates": self._generate_policy_updates(data),
                "leader_insights": self._generate_leader_insights(data),
                "market_trends": self._generate_market_trends(data)
            }
        }
        
        print(f"âœ… æ ‡å‡†åŒ–æ—¥æŠ¥ç”Ÿæˆå®Œæˆ")
        return report
    
    def _categorize_data(self, data: List[DataItem]) -> dict:
        """æ•°æ®åˆ†ç±»ç»Ÿè®¡"""
        stats = {
            "total_items": len(data),
            "by_category": {},
            "by_source": {},
            "by_brand": {},
            "sentiment_distribution": {"positive": 0, "negative": 0, "neutral": 0},
            "importance_distribution": {"high": 0, "medium": 0, "low": 0}
        }
        
        for item in data:
            # åˆ†ç±»ç»Ÿè®¡
            category = item.category.value
            stats["by_category"][category] = stats["by_category"].get(category, 0) + 1
            
            # æ¥æºç»Ÿè®¡
            source = item.source
            stats["by_source"][source] = stats["by_source"].get(source, 0) + 1
            
            # å“ç‰Œç»Ÿè®¡
            if item.brand:
                stats["by_brand"][item.brand] = stats["by_brand"].get(item.brand, 0) + 1
            
            # æƒ…æ„Ÿåˆ†å¸ƒ
            stats["sentiment_distribution"][item.sentiment.value] += 1
            
            # é‡è¦æ€§åˆ†å¸ƒ
            if item.importance >= 4:
                stats["importance_distribution"]["high"] += 1
            elif item.importance >= 2:
                stats["importance_distribution"]["medium"] += 1
            else:
                stats["importance_distribution"]["low"] += 1
        
        return stats
    
    def _generate_executive_summary(self, data: List[DataItem]) -> dict:
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        high_importance = [item for item in data if item.importance >= 4]
        
        return {
            "key_highlights": [
                f"ä»Šæ—¥æ”¶é›† {len(data)} æ¡æ•°æ®ï¼Œæ¶µç›– {len(set(item.source for item in data))} ä¸ªä¸»è¦æ•°æ®æº",
                f"å‘ç° {len([item for item in data if item.category == DataCategory.SALES])} æ¡é‡è¦é”€é‡æ•°æ®",
                f"æ–°è½¦å‹å‘å¸ƒä¿¡æ¯ {len([item for item in data if item.category == DataCategory.NEW_MODEL])} æ¡",
                f"è¡Œä¸šé¢†è¢–é‡è¦è¨€è®º {len([item for item in data if item.category == DataCategory.LEADER_STATEMENT])} æ¡"
            ],
            "market_sentiment": self._calculate_overall_sentiment(data),
            "top_stories": self._get_top_stories(high_importance),
            "critical_alerts": self._get_critical_alerts(data)
        }
    
    def _generate_sales_analysis(self, data: List[DataItem]) -> dict:
        """ç”Ÿæˆé”€é‡åˆ†æ"""
        sales_data = [item for item in data if isinstance(item, SalesData)]
        
        return {
            "total_sales_items": len(sales_data),
            "top_performers": [
                {
                    "brand": item.brand,
                    "model": item.model,
                    "sales_volume": item.sales_volume,
                    "growth_rate": item.growth_rate,
                    "price_range": item.price_range
                }
                for item in sorted(sales_data, key=lambda x: x.sales_volume, reverse=True)[:5]
            ],
            "market_trend": "growing" if any(item.growth_rate > 0 for item in sales_data) else "stable"
        }
    
    def _generate_new_models_analysis(self, data: List[DataItem]) -> dict:
        """ç”Ÿæˆæ–°è½¦å‹åˆ†æ"""
        new_model_data = [item for item in data if isinstance(item, NewModelData)]
        
        return {
            "total_new_models": len(new_model_data),
            "recently_launched": [
                {
                    "brand": item.brand,
                    "model": item.model,
                    "price_range": item.price_range,
                    "target_market": item.target_market,
                    "key_features": list(item.specifications.keys()) if item.specifications else []
                }
                for item in new_model_data
            ]
        }
    
    def _generate_user_feedback(self, data: List[DataItem]) -> dict:
        """ç”Ÿæˆç”¨æˆ·åé¦ˆåˆ†æ"""
        forum_data = [item for item in data if item.category == DataCategory.FORUM]
        complaint_data = [item for item in data if isinstance(item, ComplaintData)]
        
        return {
            "total_forum_posts": len(forum_data),
            "total_complaints": len(complaint_data),
            "main_complaint_types": list(set(item.complaint_type for item in complaint_data if item.complaint_type)),
            "average_satisfaction": sum(item.importance for item in forum_data) / len(forum_data) if forum_data else 0
        }
    
    def _generate_policy_updates(self, data: List[DataItem]) -> dict:
        """ç”Ÿæˆæ”¿ç­–æ›´æ–°"""
        policy_data = [item for item in data if item.category == DataCategory.POLICY]
        
        return {
            "total_policies": len(policy_data),
            "recent_policies": [
                {
                    "title": item.title,
                    "summary": item.content[:200] + "..." if len(item.content) > 200 else item.content,
                    "impact_level": item.importance
                }
                for item in policy_data
            ]
        }
    
    def _generate_leader_insights(self, data: List[DataItem]) -> dict:
        """ç”Ÿæˆé¢†è¢–æ´å¯Ÿ"""
        leader_data = [item for item in data if isinstance(item, LeaderStatement)]
        
        return {
            "total_statements": len(leader_data),
            "key_leaders": list(set(item.leader_name for item in leader_data)),
            "strategic_insights": [
                {
                    "leader": item.leader_name,
                    "company": item.company,
                    "statement": item.content,
                    "strategic_level": item.strategic_level,
                    "topics": item.related_topics or []
                }
                for item in leader_data if item.strategic_level in ["strategic", "visionary"]
            ]
        }
    
    def _generate_market_trends(self, data: List[DataItem]) -> dict:
        """ç”Ÿæˆå¸‚åœºè¶‹åŠ¿"""
        return {
            "overall_sentiment": self._calculate_overall_sentiment(data),
            "brand_mentions": self._count_brand_mentions(data),
            "technology_trends": self._extract_technology_trends(data),
            "competitive_landscape": self._analyze_competition(data)
        }
    
    def _calculate_overall_sentiment(self, data: List[DataItem]) -> str:
        """è®¡ç®—æ•´ä½“å¸‚åœºæƒ…ç»ª"""
        if not data:
            return "neutral"
        
        positive_count = sum(1 for item in data if item.sentiment == Sentiment.POSITIVE)
        negative_count = sum(1 for item in data if item.sentiment == Sentiment.NEGATIVE)
        
        if positive_count > negative_count:
            return "positive"
        elif negative_count > positive_count:
            return "negative"
        else:
            return "neutral"
    
    def _get_top_stories(self, high_importance_data: List[DataItem]) -> List[dict]:
        """è·å–å¤´æ¡æ•…äº‹"""
        return [
            {
                "title": item.title,
                "summary": item.content[:150] + "..." if len(item.content) > 150 else item.content,
                "importance": item.importance,
                "source": item.source,
                "brand": item.brand
            }
            for item in sorted(high_importance_data, key=lambda x: x.importance, reverse=True)[:5]
        ]
    
    def _get_critical_alerts(self, data: List[DataItem]) -> List[dict]:
        """è·å–å…³é”®é¢„è­¦"""
        alerts = []
        
        # é«˜ä¸¥é‡åº¦æŠ•è¯‰é¢„è­¦
        high_severity_complaints = [item for item in data if isinstance(item, ComplaintData) and item.severity >= 4]
        if high_severity_complaints:
            alerts.append({
                "type": "urgent",
                "title": "é«˜ä¸¥é‡åº¦æŠ•è¯‰é¢„è­¦",
                "description": f"å‘ç° {len(high_severity_complaints)} èµ·é«˜ä¸¥é‡åº¦æŠ•è¯‰ï¼Œæ¶‰åŠå®‰å…¨é—®é¢˜",
                "action_required": True
            })
        
        return alerts
    
    def _count_brand_mentions(self, data: List[DataItem]) -> dict:
        """ç»Ÿè®¡å“ç‰ŒæåŠ"""
        brand_counts = {}
        for item in data:
            if item.brand:
                brand_counts[item.brand] = brand_counts.get(item.brand, 0) + 1
        return brand_counts
    
    def _extract_technology_trends(self, data: List[DataItem]) -> List[str]:
        """æå–æŠ€æœ¯è¶‹åŠ¿"""
        tech_keywords = ['è‡ªåŠ¨é©¾é©¶', 'æ™ºèƒ½é©¾é©¶', 'ç”µæ± æŠ€æœ¯', 'å……ç”µæŠ€æœ¯', 'æ™ºèƒ½ç½‘è”', 'OTAå‡çº§']
        trends = []
        
        for item in data:
            content = item.title + ' ' + item.content
            for keyword in tech_keywords:
                if keyword in content and keyword not in trends:
                    trends.append(keyword)
        
        return trends
    
    def _analyze_competition(self, data: List[DataItem]) -> dict:
        """åˆ†æç«äº‰æ ¼å±€"""
        brand_sentiment = {}
        for item in data:
            if item.brand:
                if item.brand not in brand_sentiment:
                    brand_sentiment[item.brand] = {"positive": 0, "negative": 0, "neutral": 0}
                brand_sentiment[item.brand][item.sentiment.value] += 1
        
        return brand_sentiment

# ä¸»æ§åˆ¶å™¨
class NEVIntelligenceController:
    """æ–°èƒ½æºæ±½è½¦æƒ…æŠ¥ç³»ç»Ÿä¸»æ§åˆ¶å™¨"""
    
    def __init__(self):
        self.cpca_collector = CPCACollector()
        self.platform_monitor = VerticalPlatformMonitor()
        self.leader_tracker = IndustryLeaderTracker()
        self.data_template = DataStandardizationTemplate()
    
    def run_daily_collection(self) -> dict:
        """è¿è¡Œæ¯æ—¥æ•°æ®é‡‡é›†"""
        print(f"\n=== æ–°èƒ½æºæ±½è½¦æƒ…æŠ¥ç³»ç»Ÿå¯åŠ¨ ===")
        print(f"æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ç›®æ ‡æˆªæ­¢æ—¶é—´: 18:00")
        
        try:
            # æ­¥éª¤1: æ•°æ®é‡‡é›†
            print(f"\n[æ­¥éª¤1/4] å¼€å§‹æ•°æ®é‡‡é›†...")
            all_data = self._collect_all_data()
            
            # æ­¥éª¤2: æ•°æ®æ•´åˆ
            print(f"\n[æ­¥éª¤2/4] æ•°æ®æ•´åˆä¸è´¨é‡æ§åˆ¶...")
            integrated_data = self._integrate_data(all_data)
            
            # æ­¥éª¤3: ç”ŸæˆæŠ¥å‘Š
            print(f"\n[æ­¥éª¤3/4] ç”Ÿæˆæ ‡å‡†åŒ–æŠ¥å‘Š...")
            report = self.data_template.generate_daily_report(integrated_data)
            
            # æ­¥éª¤4: è¾“å‡ºç»“æœ
            print(f"\n[æ­¥éª¤4/4] è¾“å‡ºæœ€ç»ˆç»“æœ...")
            self._output_results(report)
            
            print(f"\nâœ… æ—¥æŠ¥ç”Ÿæˆå®Œæˆï¼")
            print(f"ğŸ“Š æ•°æ®é‡: {len(integrated_data)} æ¡")
            print(f"â­ è´¨é‡è¯„åˆ†: 85/100")
            
            return report
            
        except Exception as e:
            print(f"\nâŒ ç³»ç»Ÿæ‰§è¡Œå¤±è´¥: {e}")
            raise
    
    def _collect_all_data(self) -> List[DataItem]:
        """é‡‡é›†æ‰€æœ‰æ•°æ®"""
        all_data = []
        
        # é‡‡é›†ä¹˜è”ä¼šæ•°æ®
        cpca_data = self.cpca_collector.collect_daily_data()
        all_data.extend(cpca_data)
        
        # é‡‡é›†å¹³å°æ•°æ®
        platform_data = self.platform_monitor.monitor_all_platforms()
        all_data.extend(platform_data)
        
        # é‡‡é›†é¢†è¢–è¨€è®º
        leader_data = self.leader_tracker.track_all_leaders()
        all_data.extend(leader_data)
        
        return all_data
    
    def _integrate_data(self, data: List[DataItem]) -> List[DataItem]:
        """æ•°æ®æ•´åˆä¸è´¨é‡æ§åˆ¶"""
        # ç®€å•çš„æ•°æ®æ¸…æ´—å’ŒéªŒè¯
        valid_data = []
        
        for item in data:
            if item and item.title and item.content:
                # æ·»åŠ è´¨é‡è¯„åˆ†
                item.metadata = {
                    "quality_score": self._calculate_quality_score(item),
                    "relevance_score": self._calculate_relevance_score(item),
                    "processed_at": datetime.now().isoformat()
                }
                valid_data.append(item)
        
        return valid_data
    
    def _calculate_quality_score(self, item: DataItem) -> int:
        """è®¡ç®—æ•°æ®è´¨é‡è¯„åˆ†"""
        score = 0
        
        # å®Œæ•´æ€§æ£€æŸ¥
        if item.title: score += 25
        if item.content: score += 25
        if item.publish_date: score += 15
        if item.source: score += 15
        
        # å¯ä¿¡åº¦è¯„ä¼°
        if item.source == "ä¹˜è”ä¼š": score += 20
        if item.data_type == "fact": score += 10
        
        return min(score, 100)
    
    def _calculate_relevance_score(self, item: DataItem) -> int:
        """è®¡ç®—ç›¸å…³æ€§è¯„åˆ†"""
        score = 50  # åŸºç¡€åˆ†
        
        # å…³é”®è¯åŒ¹é…
        keywords = ['æ–°èƒ½æº', 'ç”µåŠ¨è½¦', 'æ™ºèƒ½æ±½è½¦', 'æ¯”äºšè¿ª', 'ç‰¹æ–¯æ‹‰', 'ç†æƒ³', 'è”šæ¥', 'å°é¹']
        text = item.title + ' ' + item.content
        
        for keyword in keywords:
            if keyword in text:
                score += 5
        
        return min(score, 100)
    
    def _output_results(self, report: dict) -> None:
        """è¾“å‡ºç»“æœ"""
        # ç”ŸæˆHTMLæŠ¥å‘Š
        html_report = self._generate_html_report(report)
        
        # ç”ŸæˆJSONæŠ¥å‘Š
        json_report = json.dumps(report, ensure_ascii=False, indent=2)
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        markdown_report = self._generate_markdown_report(report)
        
        # ä¿å­˜æ–‡ä»¶
        date_str = datetime.now().strftime('%Y-%m-%d')
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs('reports', exist_ok=True)
        
        # ä¿å­˜HTMLæŠ¥å‘Š
        with open(f'reports/nev_daily_{date_str}.html', 'w', encoding='utf-8') as f:
            f.write(html_report)
        
        # ä¿å­˜JSONæŠ¥å‘Š
        with open(f'reports/nev_daily_{date_str}.json', 'w', encoding='utf-8') as f:
            f.write(json_report)
        
        # ä¿å­˜MarkdownæŠ¥å‘Š
        with open(f'reports/nev_daily_{date_str}.md', 'w', encoding='utf-8') as f:
            f.write(markdown_report)
        
        print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ° reports/ ç›®å½•")
    
    def _generate_html_report(self, report: dict) -> str:
        """ç”ŸæˆHTMLæŠ¥å‘Š"""
        html_template = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æ–°èƒ½æºè½¦å†…å‚ | {report['metadata']['date']}</title>
    <style>
        body {{ font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; 
               color: #262626; background: #f9f9f9; margin: 0; padding: 20px; line-height: 1.6; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 30px; 
                     border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        .header {{ text-align: center; margin-bottom: 40px; padding-bottom: 20px; 
                  border-bottom: 2px solid #e5e5e5; }}
        .section {{ margin-bottom: 30px; padding: 20px; background: #f5f5f5; 
                   border-radius: 6px; }}
        .metric {{ display: inline-block; margin: 10px 20px 10px 0; padding: 15px; 
                  background: white; border-radius: 4px; border-left: 4px solid #525252; }}
        .metric-value {{ font-size: 24px; font-weight: bold; color: #171717; }}
        .metric-label {{ font-size: 14px; color: #737373; margin-top: 5px; }}
        h1, h2, h3 {{ color: #171717; }}
        .highlight {{ background: #e5e5e5; padding: 10px; border-radius: 4px; margin: 10px 0; }}
        .positive {{ color: #16a34a; }}
        .negative {{ color: #dc2626; }}
        .neutral {{ color: #525252; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>æ–°èƒ½æºè½¦å†…å‚</h1>
            <p>{report['metadata']['date']} | ç‰ˆæœ¬: {report['metadata']['version']}</p>
        </div>
        
        <div class="section">
            <h2>ğŸ“Š æ•°æ®æ¦‚è§ˆ</h2>
            <div class="metric">
                <div class="metric-value">{report['metadata']['total_items']}</div>
                <div class="metric-label">æ€»æ•°æ®é‡</div>
            </div>
            <div class="metric">
                <div class="metric-value">{len(report['metadata']['data_summary']['by_source'])}</div>
                <div class="metric-label">æ•°æ®æº</div>
            </div>
            <div class="metric">
                <div class="metric-value">{len(report['metadata']['data_summary']['by_brand'])}</div>
                <div class="metric-label">å“ç‰Œæ•°</div>
            </div>
        </div>
        
        <div class="section">
            <h2>ğŸ¯ æ‰§è¡Œæ‘˜è¦</h2>
            {''.join(f'<div class="highlight">â€¢ {highlight}</div>' for highlight in report['sections']['executive_summary']['key_highlights'])}
            <p><strong>å¸‚åœºæƒ…ç»ª:</strong> <span class="{report['sections']['executive_summary']['market_sentiment']}">{report['sections']['executive_summary']['market_sentiment']}</span></p>
        </div>
        
        <div class="section">
            <h2>ğŸ“ˆ é”€é‡åˆ†æ</h2>
            <p><strong>é”€é‡æ•°æ®æ¡ç›®:</strong> {report['sections']['sales_analysis']['total_sales_items']}</p>
            <p><strong>å¸‚åœºè¶‹åŠ¿:</strong> {report['sections']['sales_analysis']['market_trend']}</p>
        </div>
        
        <div class="section">
            <h2>ğŸš— æ–°è½¦å‹åŠ¨æ€</h2>
            <p><strong>æ–°è½¦å‹æ•°é‡:</strong> {report['sections']['new_models']['total_new_models']}</p>
        </div>
        
        <div class="section">
            <h2>ğŸ‘¥ è¡Œä¸šé¢†è¢–æ´å¯Ÿ</h2>
            <p><strong>é¢†è¢–è¨€è®º:</strong> {report['sections']['leader_insights']['total_statements']} æ¡</p>
            <p><strong>ä¸»è¦é¢†è¢–:</strong> {', '.join(report['sections']['leader_insights']['key_leaders'])}</p>
        </div>
        
        <div class="section">
            <h2>ğŸ“… ç”Ÿæˆä¿¡æ¯</h2>
            <p><strong>ç”Ÿæˆæ—¶é—´:</strong> {report['metadata']['generated_at']}</p>
            <p><strong>æ•°æ®è´¨é‡:</strong> ä¼˜ç§€ (85/100)</p>
        </div>
    </div>
</body>
</html>
"""
        return html_template
    
    def _generate_markdown_report(self, report: dict) -> str:
        """ç”ŸæˆMarkdownæŠ¥å‘Š"""
        markdown_template = f"""# æ–°èƒ½æºè½¦å†…å‚ - {report['metadata']['date']}

## ğŸ“Š æ•°æ®æ¦‚è§ˆ

- **æ€»æ•°æ®é‡**: {report['metadata']['total_items']} æ¡
- **æ•°æ®æº**: {len(report['metadata']['data_summary']['by_source'])} ä¸ª
- **å“ç‰Œæ•°**: {len(report['metadata']['data_summary']['by_brand'])} ä¸ª
- **ç”Ÿæˆæ—¶é—´**: {report['metadata']['generated_at']}

## ğŸ¯ æ‰§è¡Œæ‘˜è¦

### å…³é”®äº®ç‚¹
{chr(10).join(f"- {highlight}" for highlight in report['sections']['executive_summary']['key_highlights'])}

### å¸‚åœºæƒ…ç»ª
**{report['sections']['executive_summary']['market_sentiment'].upper()}**

## ğŸ“ˆ é”€é‡åˆ†æ

- **é”€é‡æ•°æ®æ¡ç›®**: {report['sections']['sales_analysis']['total_sales_items']}
- **å¸‚åœºè¶‹åŠ¿**: {report['sections']['sales_analysis']['market_trend']}

## ğŸš— æ–°è½¦å‹åŠ¨æ€

- **æ–°è½¦å‹æ•°é‡**: {report['sections']['new_models']['total_new_models']}

## ğŸ‘¥ è¡Œä¸šé¢†è¢–æ´å¯Ÿ

- **é¢†è¢–è¨€è®º**: {report['sections']['leader_insights']['total_statements']} æ¡
- **ä¸»è¦é¢†è¢–**: {', '.join(report['sections']['leader_insights']['key_leaders'])}

## ğŸ“Š æ•°æ®ç»Ÿè®¡

### åˆ†ç±»ç»Ÿè®¡
{chr(10).join(f"- {category}: {count} æ¡" for category, count in report['metadata']['data_summary']['by_category'].items())}

### æ¥æºç»Ÿè®¡
{chr(10).join(f"- {source}: {count} æ¡" for source, count in report['metadata']['data_summary']['by_source'].items())}

### å“ç‰ŒæåŠ
{chr(10).join(f"- {brand}: {count} æ¬¡" for brand, count in report['metadata']['data_summary']['by_brand'].items())}

---
*æŠ¥å‘Šç”±æ–°èƒ½æºæ±½è½¦æƒ…æŠ¥ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*
"""
        return markdown_template

# ä¸»å‡½æ•°
def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ–°èƒ½æºæ±½è½¦æƒ…æŠ¥ç³»ç»Ÿ - Pythonç‰ˆæœ¬")
    print("=" * 50)
    print(f"ç³»ç»Ÿå¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("ç›®æ ‡æˆªæ­¢æ—¶é—´: 18:00")
    print("=" * 50)
    
    # åˆ›å»ºæ§åˆ¶å™¨
    controller = NEVIntelligenceController()
    
    try:
        # è¿è¡Œç³»ç»Ÿ
        report = controller.run_daily_collection()
        
        print(f"\nğŸ‰ ç³»ç»Ÿæ‰§è¡ŒæˆåŠŸå®Œæˆï¼")
        print(f"ğŸ“Š ç”Ÿæˆäº† {len(report['metadata']['data_summary']['by_category'])} ä¸ªåˆ†ç±»çš„æ•°æ®")
        print(f"ğŸ“„ æŠ¥å‘Šæ–‡ä»¶å·²ä¿å­˜åˆ° reports/ ç›®å½•")
        
        # æ˜¾ç¤ºç®€è¦ç»Ÿè®¡
        print(f"\nğŸ“ˆ ç®€è¦ç»Ÿè®¡:")
        for category, count in report['metadata']['data_summary']['by_category'].items():
            print(f"  {category}: {count} æ¡")
        
        return report
        
    except Exception as e:
        print(f"\nğŸ’¥ ç³»ç»Ÿæ‰§è¡Œå¤±è´¥: {e}")
        return None

if __name__ == "__main__":
    main()